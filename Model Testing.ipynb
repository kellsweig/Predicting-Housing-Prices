{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1a185e6-22f0-4ae9-8a0d-126d683d17dd",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Play around with different models\n",
    "\n",
    "I have 4 initial clean dataframes for 'big' models that till have many columns:\n",
    "1. df1 = missing values dropped, and category 1 columns dropped\n",
    "2. df2 = missing values dropped, and category 1 & 2 columns dropped\n",
    "3. df3 = missing values dropped, and cat1 dropped\n",
    "4. df4 = missing values dropped, and cat 1 & 2 dropped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c426f7-c582-4134-934e-edcc4a5217d6",
   "metadata": {},
   "source": [
    "Imports, read in data, start with overfit models and then simplify. Afterwards, start with simpler model and work my way up. Look back at heatmaps to eliminate more columns/ examine coefficients and p-values within df to eliminate more columns.\n",
    "\n",
    "Basic Steps for each model:\n",
    "1. Define X and y (Remove ID variables) \n",
    "2. Train-test split\n",
    "3. Pre-processing\n",
    "    - One hot encoding\n",
    "    - Simple Imputer (for df3 & df4)\n",
    "    - Interaction Variables/ Polynomial Features (try with and without)\n",
    "    - Manually create some interaction variables\n",
    "4. Instantiate Linear Regression Model\n",
    "5. Analyze scores & submit to Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "408c2304-a3d5-46b7-906b-677a6fb7ae34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c37cf9d5-ae1d-42ec-adcc-0c9c646618de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1 with df1 (simplest clean dataset- missings dropped, some columns dropped)\n",
    "\n",
    "df1 = pd.read_csv('datasets/df1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ee7d8f9-9ad9-4e66-821e-497fbd2696da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Id</th>\n",
       "      <th>PID</th>\n",
       "      <th>MS SubClass</th>\n",
       "      <th>MS Zoning</th>\n",
       "      <th>Lot Frontage</th>\n",
       "      <th>Lot Area</th>\n",
       "      <th>Street</th>\n",
       "      <th>Lot Shape</th>\n",
       "      <th>Land Contour</th>\n",
       "      <th>...</th>\n",
       "      <th>Enclosed Porch</th>\n",
       "      <th>3Ssn Porch</th>\n",
       "      <th>Screen Porch</th>\n",
       "      <th>Pool Area</th>\n",
       "      <th>Fence</th>\n",
       "      <th>Misc Val</th>\n",
       "      <th>Mo Sold</th>\n",
       "      <th>Yr Sold</th>\n",
       "      <th>Sale Type</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>544</td>\n",
       "      <td>531379050</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>43.0</td>\n",
       "      <td>11492</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>220000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>153</td>\n",
       "      <td>535304180</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>7922</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>109000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>318</td>\n",
       "      <td>916386060</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>73.0</td>\n",
       "      <td>9802</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>174000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>255</td>\n",
       "      <td>906425045</td>\n",
       "      <td>50</td>\n",
       "      <td>RL</td>\n",
       "      <td>82.0</td>\n",
       "      <td>14235</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>138500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>138</td>\n",
       "      <td>535126040</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>137.0</td>\n",
       "      <td>16492</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>190000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   Id        PID  MS SubClass MS Zoning  Lot Frontage  Lot Area  \\\n",
       "0           1  544  531379050           60        RL          43.0     11492   \n",
       "1           2  153  535304180           20        RL          68.0      7922   \n",
       "2           3  318  916386060           60        RL          73.0      9802   \n",
       "3           4  255  906425045           50        RL          82.0     14235   \n",
       "4           5  138  535126040           20        RL         137.0     16492   \n",
       "\n",
       "  Street Lot Shape Land Contour  ... Enclosed Porch 3Ssn Porch Screen Porch  \\\n",
       "0   Pave       IR1          Lvl  ...              0          0            0   \n",
       "1   Pave       Reg          Lvl  ...              0          0            0   \n",
       "2   Pave       Reg          Lvl  ...              0          0            0   \n",
       "3   Pave       IR1          Lvl  ...              0          0            0   \n",
       "4   Pave       IR1          Lvl  ...              0          0            0   \n",
       "\n",
       "  Pool Area Fence Misc Val  Mo Sold  Yr Sold  Sale Type  SalePrice  \n",
       "0         0   NaN        0        4     2009        WD      220000  \n",
       "1         0   NaN        0        1     2010        WD      109000  \n",
       "2         0   NaN        0        4     2010        WD      174000  \n",
       "3         0   NaN        0        3     2010        WD      138500  \n",
       "4         0   NaN        0        6     2010        WD      190000  \n",
       "\n",
       "[5 rows x 75 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cf638b0-9621-4a51-863d-4b63631b51b6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1598, 75)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "853e4b7f-a763-4c3d-84fd-49c783b02ec6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df1_X = df1.drop(columns=['Unnamed: 0', 'Id', 'PID', 'SalePrice'])\n",
    "df1_y = df1['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3a3ae48-d1a4-4e2c-81c4-f94a9d841cce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X1_train, X1_test, y1_train, y1_test = train_test_split(df1_X, df1_y, test_size= 0.2, random_state=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "552f9e78-bd48-4603-a1b4-ae34473d47cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Make lists of the numeric and string columns:\n",
    "df1_str = list(df1_X.select_dtypes(include=['object']).columns)\n",
    "df1_num = list(df1_X.select_dtypes(include=['int', 'float']).columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f4c04cb-c684-48d9-8073-d779be905c4d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found unknown categories ['Mansard'] in column 10 during transform",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m X1_train_transformed \u001b[38;5;241m=\u001b[39m ct\u001b[38;5;241m.\u001b[39mfit_transform(X1_train)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Transform the test data using the fitted ColumnTransformer\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m X1_test_transformed \u001b[38;5;241m=\u001b[39m ct\u001b[38;5;241m.\u001b[39mtransform(X1_test)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:816\u001b[0m, in \u001b[0;36mColumnTransformer.transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    811\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    812\u001b[0m     \u001b[38;5;66;03m# ndarray was used for fitting or transforming, thus we only\u001b[39;00m\n\u001b[0;32m    813\u001b[0m     \u001b[38;5;66;03m# check that n_features_in_ is consistent\u001b[39;00m\n\u001b[0;32m    814\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_n_features(X, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m--> 816\u001b[0m Xs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_transform(\n\u001b[0;32m    817\u001b[0m     X,\n\u001b[0;32m    818\u001b[0m     \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    819\u001b[0m     _transform_one,\n\u001b[0;32m    820\u001b[0m     fitted\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    821\u001b[0m     column_as_strings\u001b[38;5;241m=\u001b[39mfit_dataframe_and_transform_dataframe,\n\u001b[0;32m    822\u001b[0m )\n\u001b[0;32m    823\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_output(Xs)\n\u001b[0;32m    825\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Xs:\n\u001b[0;32m    826\u001b[0m     \u001b[38;5;66;03m# All transformers are None\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:670\u001b[0m, in \u001b[0;36mColumnTransformer._fit_transform\u001b[1;34m(self, X, y, func, fitted, column_as_strings)\u001b[0m\n\u001b[0;32m    664\u001b[0m transformers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[0;32m    665\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter(\n\u001b[0;32m    666\u001b[0m         fitted\u001b[38;5;241m=\u001b[39mfitted, replace_strings\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, column_as_strings\u001b[38;5;241m=\u001b[39mcolumn_as_strings\n\u001b[0;32m    667\u001b[0m     )\n\u001b[0;32m    668\u001b[0m )\n\u001b[0;32m    669\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 670\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Parallel(n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)(\n\u001b[0;32m    671\u001b[0m         delayed(func)(\n\u001b[0;32m    672\u001b[0m             transformer\u001b[38;5;241m=\u001b[39mclone(trans) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fitted \u001b[38;5;28;01melse\u001b[39;00m trans,\n\u001b[0;32m    673\u001b[0m             X\u001b[38;5;241m=\u001b[39m_safe_indexing(X, column, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m    674\u001b[0m             y\u001b[38;5;241m=\u001b[39my,\n\u001b[0;32m    675\u001b[0m             weight\u001b[38;5;241m=\u001b[39mweight,\n\u001b[0;32m    676\u001b[0m             message_clsname\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumnTransformer\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    677\u001b[0m             message\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_message(name, idx, \u001b[38;5;28mlen\u001b[39m(transformers)),\n\u001b[0;32m    678\u001b[0m         )\n\u001b[0;32m    679\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m idx, (name, trans, column, weight) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(transformers, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    680\u001b[0m     )\n\u001b[0;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    682\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got 1D array instead\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mapply_async(batch, callback\u001b[38;5;241m=\u001b[39mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m batch()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py:933\u001b[0m, in \u001b[0;36m_transform_one\u001b[1;34m(transformer, X, y, weight, **fit_params)\u001b[0m\n\u001b[0;32m    932\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_transform_one\u001b[39m(transformer, X, y, weight, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params):\n\u001b[1;32m--> 933\u001b[0m     res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[0;32m    934\u001b[0m     \u001b[38;5;66;03m# if we have a weight for this transformer, multiply output\u001b[39;00m\n\u001b[0;32m    935\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:1016\u001b[0m, in \u001b[0;36mOneHotEncoder.transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1011\u001b[0m \u001b[38;5;66;03m# validation of X happens in _check_X called by _transform\u001b[39;00m\n\u001b[0;32m   1012\u001b[0m warn_on_unknown \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_unknown \u001b[38;5;129;01min\u001b[39;00m {\n\u001b[0;32m   1013\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1014\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minfrequent_if_exist\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1015\u001b[0m }\n\u001b[1;32m-> 1016\u001b[0m X_int, X_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform(\n\u001b[0;32m   1017\u001b[0m     X,\n\u001b[0;32m   1018\u001b[0m     handle_unknown\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_unknown,\n\u001b[0;32m   1019\u001b[0m     force_all_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1020\u001b[0m     warn_on_unknown\u001b[38;5;241m=\u001b[39mwarn_on_unknown,\n\u001b[0;32m   1021\u001b[0m )\n\u001b[0;32m   1023\u001b[0m n_samples, n_features \u001b[38;5;241m=\u001b[39m X_int\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m   1025\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_drop_idx_after_grouping \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:199\u001b[0m, in \u001b[0;36m_BaseEncoder._transform\u001b[1;34m(self, X, handle_unknown, force_all_finite, warn_on_unknown, ignore_category_indices)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handle_unknown \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    195\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    196\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound unknown categories \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m in column \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    197\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m during transform\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(diff, i)\n\u001b[0;32m    198\u001b[0m     )\n\u001b[1;32m--> 199\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m warn_on_unknown:\n",
      "\u001b[1;31mValueError\u001b[0m: Found unknown categories ['Mansard'] in column 10 during transform"
     ]
    }
   ],
   "source": [
    "ct = ColumnTransformer([\n",
    "    ('poly', PolynomialFeatures(include_bias=False), df1_num),\n",
    "    ('scaler', StandardScaler(), df1_num), \n",
    "    ('oh', OneHotEncoder(sparse_output=False, drop='first'), df1_str)\n",
    "], remainder='passthrough')  # 'passthrough' allows non-transformed columns to pass through\n",
    "\n",
    "# Fit and transform the training data using the ColumnTransformer\n",
    "X1_train_transformed = ct.fit_transform(X1_train)\n",
    "\n",
    "# Transform the test data using the fitted ColumnTransformer\n",
    "X1_test_transformed = ct.transform(X1_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f111cd-3d4a-4be8-b296-01e1cfb3829d",
   "metadata": {},
   "source": [
    "#Pre-processing:\n",
    "#Referred to lesson 305 Feature Engineering\n",
    "ct = ColumnTransformer([\n",
    "    ('poly', PolynomialFeatures(include_bias=False), df1_num),\n",
    "    ('oh', OneHotEncoder(sparse_output=False, drop='first'), df1_str)\n",
    "], remainder='drop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf78f250-138b-43ce-8b7a-04c2ea89ad8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#lr = LinearRegression()\n",
    "#lr.fit(df1_X, df1_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9561278e-b039-4219-b80b-25a9c48abe67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc63627-77a3-45dd-9d6c-8040ebd86c38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3209fab9-cc56-4333-80fe-fd1af68ea642",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4514ab94-1c33-4b0c-95cc-4053f986b83a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df5 = pd.read_csv('datasets/df5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f946901-27d7-42c0-9cb2-0d0c4098cff9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>SalePrice</th>\n",
       "      <th>Id</th>\n",
       "      <th>Overall Qual</th>\n",
       "      <th>Gr Liv Area</th>\n",
       "      <th>Garage Area</th>\n",
       "      <th>Garage Cars</th>\n",
       "      <th>Total Bsmt SF</th>\n",
       "      <th>1st Flr SF</th>\n",
       "      <th>Year Built</th>\n",
       "      <th>...</th>\n",
       "      <th>BsmtFin SF 1</th>\n",
       "      <th>Wood Deck SF</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>Condition 1</th>\n",
       "      <th>Condition 2</th>\n",
       "      <th>Bldg Type</th>\n",
       "      <th>House Style</th>\n",
       "      <th>Overall Cond</th>\n",
       "      <th>Functional</th>\n",
       "      <th>Sale Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>130500</td>\n",
       "      <td>109</td>\n",
       "      <td>6</td>\n",
       "      <td>1479</td>\n",
       "      <td>475.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>725.0</td>\n",
       "      <td>725</td>\n",
       "      <td>1976</td>\n",
       "      <td>...</td>\n",
       "      <td>533.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Sawyer</td>\n",
       "      <td>RRAe</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>2Story</td>\n",
       "      <td>8</td>\n",
       "      <td>Typ</td>\n",
       "      <td>WD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>220000</td>\n",
       "      <td>544</td>\n",
       "      <td>7</td>\n",
       "      <td>2122</td>\n",
       "      <td>559.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>913.0</td>\n",
       "      <td>913</td>\n",
       "      <td>1996</td>\n",
       "      <td>...</td>\n",
       "      <td>637.0</td>\n",
       "      <td>0</td>\n",
       "      <td>SawyerW</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>2Story</td>\n",
       "      <td>5</td>\n",
       "      <td>Typ</td>\n",
       "      <td>WD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>109000</td>\n",
       "      <td>153</td>\n",
       "      <td>5</td>\n",
       "      <td>1057</td>\n",
       "      <td>246.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1057.0</td>\n",
       "      <td>1057</td>\n",
       "      <td>1953</td>\n",
       "      <td>...</td>\n",
       "      <td>731.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NAmes</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>1Story</td>\n",
       "      <td>7</td>\n",
       "      <td>Typ</td>\n",
       "      <td>WD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>174000</td>\n",
       "      <td>318</td>\n",
       "      <td>5</td>\n",
       "      <td>1444</td>\n",
       "      <td>400.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>744</td>\n",
       "      <td>2006</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>Timber</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>2Story</td>\n",
       "      <td>5</td>\n",
       "      <td>Typ</td>\n",
       "      <td>WD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>138500</td>\n",
       "      <td>255</td>\n",
       "      <td>6</td>\n",
       "      <td>1445</td>\n",
       "      <td>484.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>831</td>\n",
       "      <td>1900</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>SawyerW</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>1.5Fin</td>\n",
       "      <td>8</td>\n",
       "      <td>Typ</td>\n",
       "      <td>WD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  SalePrice   Id  Overall Qual  Gr Liv Area  Garage Area  \\\n",
       "0           0     130500  109             6         1479        475.0   \n",
       "1           1     220000  544             7         2122        559.0   \n",
       "2           2     109000  153             5         1057        246.0   \n",
       "3           3     174000  318             5         1444        400.0   \n",
       "4           4     138500  255             6         1445        484.0   \n",
       "\n",
       "   Garage Cars  Total Bsmt SF  1st Flr SF  Year Built  ...  BsmtFin SF 1  \\\n",
       "0          2.0          725.0         725        1976  ...         533.0   \n",
       "1          2.0          913.0         913        1996  ...         637.0   \n",
       "2          1.0         1057.0        1057        1953  ...         731.0   \n",
       "3          2.0          384.0         744        2006  ...           0.0   \n",
       "4          2.0          676.0         831        1900  ...           0.0   \n",
       "\n",
       "   Wood Deck SF  Neighborhood  Condition 1  Condition 2  Bldg Type  \\\n",
       "0             0        Sawyer         RRAe         Norm       1Fam   \n",
       "1             0       SawyerW         Norm         Norm       1Fam   \n",
       "2             0         NAmes         Norm         Norm       1Fam   \n",
       "3           100        Timber         Norm         Norm       1Fam   \n",
       "4             0       SawyerW         Norm         Norm       1Fam   \n",
       "\n",
       "  House Style Overall Cond Functional Sale Type  \n",
       "0      2Story            8        Typ       WD   \n",
       "1      2Story            5        Typ       WD   \n",
       "2      1Story            7        Typ       WD   \n",
       "3      2Story            5        Typ       WD   \n",
       "4      1.5Fin            8        Typ       WD   \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99215b86-a717-48c1-8834-d403365a8666",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df5_X = df5.drop(columns=['Unnamed: 0', 'Id', 'SalePrice'])\n",
    "df5_y = df5['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe39d3c6-9260-43fb-b5db-46270aa399a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X5_train, X5_test, y5_train, y5_test = train_test_split(df5_X, df5_y, test_size= 0.2, random_state=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0dad5bca-b263-4afa-83b0-dfc3d469502f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df5_train_str = list(X5_train.select_dtypes(include=['object']).columns)\n",
    "df5_test_str = list(X5_test.select_dtypes(include=['object']).columns)\n",
    "df5_train_num = list(X5_train.select_dtypes(include=['int', 'float']).columns)\n",
    "df5_test_num = list(X5_test.select_dtypes(include=['int', 'float']).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53345ab-8216-40b2-b65a-0d6b75531dd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "49e5b776-ddc3-4aee-8f48-ba6f2b45dae8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No valid specification of the columns. Only a scalar, list or slice of all integers or all strings, or boolean mask is allowed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\__init__.py:278\u001b[0m, in \u001b[0;36m_determine_key_type\u001b[1;34m(key, accept_slice)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 278\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m array_dtype_to_str[key\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind]\n\u001b[0;32m    279\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "\u001b[1;31mKeyError\u001b[0m: 'f'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 12\u001b[0m\n\u001b[0;32m      5\u001b[0m ct \u001b[38;5;241m=\u001b[39m ColumnTransformer([\n\u001b[0;32m      6\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpoly\u001b[39m\u001b[38;5;124m'\u001b[39m, PolynomialFeatures(include_bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m), X5_train_transformed),\n\u001b[0;32m      7\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscaler\u001b[39m\u001b[38;5;124m'\u001b[39m, StandardScaler(), X5_train_transformed),\n\u001b[0;32m      8\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moh\u001b[39m\u001b[38;5;124m'\u001b[39m, OneHotEncoder(sparse_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfirst\u001b[39m\u001b[38;5;124m'\u001b[39m), df5_train_str)\n\u001b[0;32m      9\u001b[0m ], remainder\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Fit and transform the training data using the ColumnTransformer\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m X5_train_transformed \u001b[38;5;241m=\u001b[39m ct\u001b[38;5;241m.\u001b[39mfit_transform(X5_train)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Transform the test data using the fitted ColumnTransformer\u001b[39;00m\n\u001b[0;32m     15\u001b[0m X5_test_transformed \u001b[38;5;241m=\u001b[39m ct\u001b[38;5;241m.\u001b[39mtransform(X5_test)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:740\u001b[0m, in \u001b[0;36mColumnTransformer.fit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    738\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_n_features(X, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    739\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_transformers()\n\u001b[1;32m--> 740\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_column_callables(X)\n\u001b[0;32m    741\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_remainder(X)\n\u001b[0;32m    743\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_transform(X, y, _fit_transform_one)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:448\u001b[0m, in \u001b[0;36mColumnTransformer._validate_column_callables\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    446\u001b[0m         columns \u001b[38;5;241m=\u001b[39m columns(X)\n\u001b[0;32m    447\u001b[0m     all_columns\u001b[38;5;241m.\u001b[39mappend(columns)\n\u001b[1;32m--> 448\u001b[0m     transformer_to_input_indices[name] \u001b[38;5;241m=\u001b[39m _get_column_indices(X, columns)\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_columns \u001b[38;5;241m=\u001b[39m all_columns\n\u001b[0;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transformer_to_input_indices \u001b[38;5;241m=\u001b[39m transformer_to_input_indices\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\__init__.py:405\u001b[0m, in \u001b[0;36m_get_column_indices\u001b[1;34m(X, key)\u001b[0m\n\u001b[0;32m    398\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Get feature column indices for input data X and key.\u001b[39;00m\n\u001b[0;32m    399\u001b[0m \n\u001b[0;32m    400\u001b[0m \u001b[38;5;124;03mFor accepted values of `key`, see the docstring of\u001b[39;00m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;124;03m:func:`_safe_indexing_column`.\u001b[39;00m\n\u001b[0;32m    402\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    403\u001b[0m n_columns \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m--> 405\u001b[0m key_dtype \u001b[38;5;241m=\u001b[39m _determine_key_type(key)\n\u001b[0;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m key:\n\u001b[0;32m    408\u001b[0m     \u001b[38;5;66;03m# we get an empty list\u001b[39;00m\n\u001b[0;32m    409\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m []\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\__init__.py:280\u001b[0m, in \u001b[0;36m_determine_key_type\u001b[1;34m(key, accept_slice)\u001b[0m\n\u001b[0;32m    278\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m array_dtype_to_str[key\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind]\n\u001b[0;32m    279\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m--> 280\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(err_msg)\n\u001b[0;32m    281\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(err_msg)\n",
      "\u001b[1;31mValueError\u001b[0m: No valid specification of the columns. Only a scalar, list or slice of all integers or all strings, or boolean mask is allowed"
     ]
    }
   ],
   "source": [
    "imputer = SimpleImputer(strategy='mean')\n",
    "X5_train_transformed = imputer.fit_transform(X5_train[df5_train_num])\n",
    "\n",
    "\n",
    "ct = ColumnTransformer([\n",
    "    ('poly', PolynomialFeatures(include_bias=False), X5_train_transformed),\n",
    "    ('scaler', StandardScaler(), X5_train_transformed),\n",
    "    ('oh', OneHotEncoder(sparse_output=False, drop='first'), df5_train_str)\n",
    "], remainder='passthrough')\n",
    "\n",
    "# Fit and transform the training data using the ColumnTransformer\n",
    "X5_train_transformed = ct.fit_transform(X5_train)\n",
    "\n",
    "# Transform the test data using the fitted ColumnTransformer\n",
    "X5_test_transformed = ct.transform(X5_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2693728b-65c1-4fb9-a899-c6e8f612a97b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9419309322015498\n",
      "0.8988941760085423\n",
      "679339772.2771369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kaitl\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:227: UserWarning: Found unknown categories in columns [2, 5] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "df6 = pd.read_csv('datasets/df5.csv')\n",
    "\n",
    "df6 = df6.dropna()\n",
    "\n",
    "df6_X = df6.drop(columns=['Unnamed: 0', 'Id', 'SalePrice'])\n",
    "df6_y = df6['SalePrice']\n",
    "\n",
    "X6_train, X6_test, y6_train, y6_test = train_test_split(df6_X, df6_y, test_size= 0.2, random_state=24)\n",
    "\n",
    "df6_train_str = list(X6_train.select_dtypes(include=['object']).columns)\n",
    "df6_test_str = list(X6_test.select_dtypes(include=['object']).columns)\n",
    "df6_train_num = list(X6_train.select_dtypes(include=['int', 'float']).columns)\n",
    "df6_test_num = list(X6_test.select_dtypes(include=['int', 'float']).columns)\n",
    "\n",
    "ct = ColumnTransformer([\n",
    "    ('poly', PolynomialFeatures(include_bias=False), df6_train_num),\n",
    "    ('scaler', StandardScaler(), df6_train_num),\n",
    "    ('oh', OneHotEncoder(sparse_output=False, handle_unknown='ignore', drop='first'), df6_train_str)\n",
    "], remainder='passthrough')\n",
    "\n",
    "# Fit and transform the training data using the ColumnTransformer\n",
    "X6_train_transformed = ct.fit_transform(X6_train)\n",
    "\n",
    "# Transform the test data using the fitted ColumnTransformer\n",
    "X6_test_transformed = ct.transform(X6_test)\n",
    "\n",
    "lr6 = LinearRegression()\n",
    "\n",
    "lr6.fit(X6_train_transformed, y6_train)\n",
    "\n",
    "r2_train = lr6.score(X6_train_transformed, y6_train)\n",
    "\n",
    "r2_test = lr6.score(X6_test_transformed, y6_test)\n",
    "\n",
    "y6_pred = lr6.predict(X6_test_transformed)\n",
    "\n",
    "print(r2_train)\n",
    "print(r2_test)\n",
    "print(metrics.mean_squared_error(y6_test, y6_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a98338-4bda-46a3-bd52-2dd955f3afa4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df6 = pd.read_csv('datasets/df5.csv')\n",
    "df6 = df6.dropna()\n",
    "df6_X = df6.drop(columns=['Unnamed: 0', 'Id', 'SalePrice'])\n",
    "df6_y = df6['SalePrice']\n",
    "X6_train, X6_test, y6_train, y6_test = train_test_split(df6_X, df6_y, test_size=0.2, random_state=24)\n",
    "df6_train_str = list(X6_train.select_dtypes(include=['object']).columns)\n",
    "df6_test_str = list(X6_test.select_dtypes(include=['object']).columns)\n",
    "df6_train_num = list(X6_train.select_dtypes(include=['int', 'float']).columns)\n",
    "df6_test_num = list(X6_test.select_dtypes(include=['int', 'float']).columns)\n",
    "\n",
    "# Create a ColumnTransformer with PolynomialFeatures, StandardScaler, and OneHotEncoder\n",
    "ct = ColumnTransformer([\n",
    "    ('poly', PolynomialFeatures(include_bias=False), df6_train_num),\n",
    "    ('scaler', StandardScaler(), df6_train_num),\n",
    "    ('oh', OneHotEncoder(sparse_output=False, drop='first'), df6_train_str)\n",
    "], remainder='passthrough')\n",
    "\n",
    "# Fit and transform the training data using the ColumnTransformer\n",
    "X6_train_transformed = ct.fit_transform(X6_train)\n",
    "\n",
    "# Transform the test data using the fitted ColumnTransformer\n",
    "X6_test_transformed = ct.transform(X6_test)\n",
    "\n",
    "# Create an ElasticNet model\n",
    "elastic_net = ElasticNet()\n",
    "param_grid = {\n",
    "    'alpha': [0.01, 0.1, 1.0, 10.0],      # Values of alpha to test\n",
    "    'l1_ratio': [0.1, 0.3, 0.5, 0.7, 0.9]  # Values of l1_ratio to test\n",
    "}\n",
    "\n",
    "# Create a GridSearchCV object\n",
    "grid_search = GridSearchCV(estimator=elastic_net, param_grid=param_grid, cv=5)\n",
    "\n",
    "# Fit the GridSearchCV object to the training data\n",
    "grid_search.fit(X6_train_transformed, y6_train)\n",
    "\n",
    "# Get the best hyperparameters from the search\n",
    "best_alpha = grid_search.best_params_['alpha']\n",
    "best_l1_ratio = grid_search.best_params_['l1_ratio']\n",
    "\n",
    "print(f\"Best alpha: {best_alpha}\")\n",
    "print(f\"Best l1_ratio: {best_l1_ratio}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe91604-46c4-4e71-bc30-9c659c8192a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df6 = pd.read_csv('datasets/df5.csv')\n",
    "df6 = df6.dropna()\n",
    "df6_X = df6.drop(columns=['Unnamed: 0', 'Id', 'SalePrice'])\n",
    "df6_y = df6['SalePrice']\n",
    "X6_train, X6_test, y6_train, y6_test = train_test_split(df6_X, df6_y, test_size=0.2, random_state=4)\n",
    "df6_train_str = list(X6_train.select_dtypes(include=['object']).columns)\n",
    "df6_test_str = list(X6_test.select_dtypes(include=['object']).columns)\n",
    "df6_train_num = list(X6_train.select_dtypes(include=['int', 'float']).columns)\n",
    "df6_test_num = list(X6_test.select_dtypes(include=['int', 'float']).columns)\n",
    "\n",
    "# Create a ColumnTransformer with PolynomialFeatures, StandardScaler, and OneHotEncoder\n",
    "ct = ColumnTransformer([\n",
    "    ('poly', PolynomialFeatures(include_bias=False), df6_train_num),\n",
    "    ('scaler', StandardScaler(), df6_train_num),\n",
    "    ('oh', OneHotEncoder(sparse_output=False, drop='first'), df6_train_str)\n",
    "], remainder='passthrough')\n",
    "\n",
    "# Fit and transform the training data using the ColumnTransformer\n",
    "X6_train_transformed = ct.fit_transform(X6_train)\n",
    "\n",
    "# Transform the test data using the fitted ColumnTransformer\n",
    "X6_test_transformed = ct.transform(X6_test)\n",
    "\n",
    "# Create an ElasticNet model with regularization\n",
    "elastic_net = ElasticNet(alpha=.01, l1_ratio=0.5)  # You can adjust alpha and l1_ratio as needed\n",
    "\n",
    "# Fit the ElasticNet model to the training data\n",
    "elastic_net.fit(X6_train_transformed, y6_train)\n",
    "\n",
    "# Calculate the R-squared score on the training and test data\n",
    "train_score = elastic_net.score(X6_train_transformed, y6_train)\n",
    "test_score = elastic_net.score(X6_test_transformed, y6_test)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y6_pred = elastic_net.predict(X6_test_transformed)\n",
    "\n",
    "# Calculate the mean squared error\n",
    "mse = metrics.mean_squared_error(y6_test, y6_pred)\n",
    "\n",
    "print(f\"Training R-squared: {train_score}\")\n",
    "print(f\"Test R-squared: {test_score}\")\n",
    "print(f\"Mean Squared Error: {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a2885d-bc78-42c1-bf2c-5bedbd5895f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df6 = pd.read_csv('datasets/df5.csv')\n",
    "df6 = df6.dropna()\n",
    "df6_X = df6.drop(columns=['Unnamed: 0', 'Id', 'SalePrice'])\n",
    "df6_y = df6['SalePrice']\n",
    "X6_train, X6_test, y6_train, y6_test = train_test_split(df6_X, df6_y, test_size=0.2, random_state=4)\n",
    "df6_train_str = list(X6_train.select_dtypes(include=['object']).columns)\n",
    "df6_test_str = list(X6_test.select_dtypes(include=['object']).columns)\n",
    "df6_train_num = list(X6_train.select_dtypes(include=['int', 'float']).columns)\n",
    "df6_test_num = list(X6_test.select_dtypes(include=['int', 'float']).columns)\n",
    "\n",
    "# Create a ColumnTransformer with PolynomialFeatures, StandardScaler, and OneHotEncoder\n",
    "ct = ColumnTransformer([\n",
    "    ('poly', PolynomialFeatures(include_bias=False), df6_train_num),\n",
    "    ('scaler', StandardScaler(), df6_train_num),\n",
    "    ('oh', OneHotEncoder(sparse_output=False, drop='first'), df6_train_str)\n",
    "], remainder='passthrough')\n",
    "\n",
    "# Fit and transform the training data using the ColumnTransformer\n",
    "X6_train_transformed = ct.fit_transform(X6_train)\n",
    "\n",
    "# Transform the test data using the fitted ColumnTransformer\n",
    "X6_test_transformed = ct.transform(X6_test)\n",
    "\n",
    "# Create a Lasso model with regularization\n",
    "lasso = Lasso(alpha=.01)  # You can adjust the alpha parameter as needed\n",
    "\n",
    "# Fit the Lasso model to the training data\n",
    "lasso.fit(X6_train_transformed, y6_train)\n",
    "\n",
    "# Calculate the R-squared score on the training and test data\n",
    "train_score = lasso.score(X6_train_transformed, y6_train)\n",
    "test_score = lasso.score(X6_test_transformed, y6_test)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y6_pred = lasso.predict(X6_test_transformed)\n",
    "\n",
    "# Calculate the mean squared error\n",
    "mse = metrics.mean_squared_error(y6_test, y6_pred)\n",
    "\n",
    "print(f\"Training R-squared: {train_score}\")\n",
    "print(f\"Test R-squared: {test_score}\")\n",
    "print(f\"Mean Squared Error: {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b13189-164a-4aea-9a43-914a675f97b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
