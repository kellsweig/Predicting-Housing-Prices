{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1a185e6-22f0-4ae9-8a0d-126d683d17dd",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Play around with different models\n",
    "\n",
    "I have 4 initial clean dataframes for 'big' models that till have many columns:\n",
    "1. df1 = missing values dropped, and category 1 columns dropped\n",
    "2. df2 = missing values dropped, and category 1 & 2 columns dropped\n",
    "3. df3 = missing values dropped, and cat1 dropped\n",
    "4. df4 = missing values dropped, and cat 1 & 2 dropped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c426f7-c582-4134-934e-edcc4a5217d6",
   "metadata": {},
   "source": [
    "Imports, read in data, start with overfit models and then simplify. Afterwards, start with simpler model and work my way up. Look back at heatmaps to eliminate more columns/ examine coefficients and p-values within df to eliminate more columns.\n",
    "\n",
    "Basic Steps for each model:\n",
    "1. Define X and y (Remove ID variables) \n",
    "2. Train-test split\n",
    "3. Pre-processing\n",
    "    - One hot encoding\n",
    "    - Simple Imputer (for df3 & df4)\n",
    "    - Interaction Variables/ Polynomial Features (try with and without)\n",
    "    - Manually create some interaction variables\n",
    "4. Instantiate Linear Regression Model\n",
    "5. Analyze scores & submit to Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "408c2304-a3d5-46b7-906b-677a6fb7ae34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c37cf9d5-ae1d-42ec-adcc-0c9c646618de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1 with df1 (simplest clean dataset- missings dropped, some columns dropped)\n",
    "\n",
    "df1 = pd.read_csv('datasets/df1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5ee7d8f9-9ad9-4e66-821e-497fbd2696da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Id</th>\n",
       "      <th>PID</th>\n",
       "      <th>MS SubClass</th>\n",
       "      <th>MS Zoning</th>\n",
       "      <th>Lot Frontage</th>\n",
       "      <th>Lot Area</th>\n",
       "      <th>Street</th>\n",
       "      <th>Lot Shape</th>\n",
       "      <th>Land Contour</th>\n",
       "      <th>...</th>\n",
       "      <th>Enclosed Porch</th>\n",
       "      <th>3Ssn Porch</th>\n",
       "      <th>Screen Porch</th>\n",
       "      <th>Pool Area</th>\n",
       "      <th>Fence</th>\n",
       "      <th>Misc Val</th>\n",
       "      <th>Mo Sold</th>\n",
       "      <th>Yr Sold</th>\n",
       "      <th>Sale Type</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>544</td>\n",
       "      <td>531379050</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>43.0</td>\n",
       "      <td>11492</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>220000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>153</td>\n",
       "      <td>535304180</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>7922</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>109000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>318</td>\n",
       "      <td>916386060</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>73.0</td>\n",
       "      <td>9802</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>174000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>255</td>\n",
       "      <td>906425045</td>\n",
       "      <td>50</td>\n",
       "      <td>RL</td>\n",
       "      <td>82.0</td>\n",
       "      <td>14235</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>138500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>138</td>\n",
       "      <td>535126040</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>137.0</td>\n",
       "      <td>16492</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>190000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   Id        PID  MS SubClass MS Zoning  Lot Frontage  Lot Area  \\\n",
       "0           1  544  531379050           60        RL          43.0     11492   \n",
       "1           2  153  535304180           20        RL          68.0      7922   \n",
       "2           3  318  916386060           60        RL          73.0      9802   \n",
       "3           4  255  906425045           50        RL          82.0     14235   \n",
       "4           5  138  535126040           20        RL         137.0     16492   \n",
       "\n",
       "  Street Lot Shape Land Contour  ... Enclosed Porch 3Ssn Porch Screen Porch  \\\n",
       "0   Pave       IR1          Lvl  ...              0          0            0   \n",
       "1   Pave       Reg          Lvl  ...              0          0            0   \n",
       "2   Pave       Reg          Lvl  ...              0          0            0   \n",
       "3   Pave       IR1          Lvl  ...              0          0            0   \n",
       "4   Pave       IR1          Lvl  ...              0          0            0   \n",
       "\n",
       "  Pool Area Fence Misc Val  Mo Sold  Yr Sold  Sale Type  SalePrice  \n",
       "0         0   NaN        0        4     2009        WD      220000  \n",
       "1         0   NaN        0        1     2010        WD      109000  \n",
       "2         0   NaN        0        4     2010        WD      174000  \n",
       "3         0   NaN        0        3     2010        WD      138500  \n",
       "4         0   NaN        0        6     2010        WD      190000  \n",
       "\n",
       "[5 rows x 75 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3cf638b0-9621-4a51-863d-4b63631b51b6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1598, 75)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "853e4b7f-a763-4c3d-84fd-49c783b02ec6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df1_X = df1.drop(columns=['Unnamed: 0', 'Id', 'PID', 'SalePrice'])\n",
    "df1_y = df1['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d3a3ae48-d1a4-4e2c-81c4-f94a9d841cce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X1_train, X1_test, y1_train, y1_test = train_test_split(df1_X, df1_y, test_size= 0.2, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "552f9e78-bd48-4603-a1b4-ae34473d47cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Make lists of the numeric and string columns:\n",
    "df1_str = list(df1_X.select_dtypes(include=['object']).columns)\n",
    "df1_num = list(df1_X.select_dtypes(include=['int', 'float']).columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7f4c04cb-c684-48d9-8073-d779be905c4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ct = ColumnTransformer([\n",
    "    ('poly', PolynomialFeatures(include_bias=False), df1_num),\n",
    "    ('scaler', StandardScaler(), df1_num), \n",
    "    ('oh', OneHotEncoder(sparse_output=False, drop='first'), df1_str)\n",
    "], remainder='passthrough')  # 'passthrough' allows non-transformed columns to pass through\n",
    "\n",
    "# Fit and transform the training data using the ColumnTransformer\n",
    "X1_train_transformed = ct.fit_transform(X1_train)\n",
    "\n",
    "# Transform the test data using the fitted ColumnTransformer\n",
    "X1_test_transformed = ct.transform(X1_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f111cd-3d4a-4be8-b296-01e1cfb3829d",
   "metadata": {},
   "source": [
    "#Pre-processing:\n",
    "#Referred to lesson 305 Feature Engineering\n",
    "ct = ColumnTransformer([\n",
    "    ('poly', PolynomialFeatures(include_bias=False), df1_num),\n",
    "    ('oh', OneHotEncoder(sparse_output=False, drop='first'), df1_str)\n",
    "], remainder='drop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cf78f250-138b-43ce-8b7a-04c2ea89ad8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#lr = LinearRegression()\n",
    "#lr.fit(df1_X, df1_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9561278e-b039-4219-b80b-25a9c48abe67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc63627-77a3-45dd-9d6c-8040ebd86c38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3209fab9-cc56-4333-80fe-fd1af68ea642",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4514ab94-1c33-4b0c-95cc-4053f986b83a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df5 = pd.read_csv('datasets/df5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7f946901-27d7-42c0-9cb2-0d0c4098cff9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>SalePrice</th>\n",
       "      <th>Id</th>\n",
       "      <th>Overall Qual</th>\n",
       "      <th>Gr Liv Area</th>\n",
       "      <th>Garage Area</th>\n",
       "      <th>Garage Cars</th>\n",
       "      <th>Total Bsmt SF</th>\n",
       "      <th>1st Flr SF</th>\n",
       "      <th>Year Built</th>\n",
       "      <th>...</th>\n",
       "      <th>BsmtFin SF 1</th>\n",
       "      <th>Wood Deck SF</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>Condition 1</th>\n",
       "      <th>Condition 2</th>\n",
       "      <th>Bldg Type</th>\n",
       "      <th>House Style</th>\n",
       "      <th>Overall Cond</th>\n",
       "      <th>Functional</th>\n",
       "      <th>Sale Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>130500</td>\n",
       "      <td>109</td>\n",
       "      <td>6</td>\n",
       "      <td>1479</td>\n",
       "      <td>475.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>725.0</td>\n",
       "      <td>725</td>\n",
       "      <td>1976</td>\n",
       "      <td>...</td>\n",
       "      <td>533.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Sawyer</td>\n",
       "      <td>RRAe</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>2Story</td>\n",
       "      <td>8</td>\n",
       "      <td>Typ</td>\n",
       "      <td>WD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>220000</td>\n",
       "      <td>544</td>\n",
       "      <td>7</td>\n",
       "      <td>2122</td>\n",
       "      <td>559.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>913.0</td>\n",
       "      <td>913</td>\n",
       "      <td>1996</td>\n",
       "      <td>...</td>\n",
       "      <td>637.0</td>\n",
       "      <td>0</td>\n",
       "      <td>SawyerW</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>2Story</td>\n",
       "      <td>5</td>\n",
       "      <td>Typ</td>\n",
       "      <td>WD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>109000</td>\n",
       "      <td>153</td>\n",
       "      <td>5</td>\n",
       "      <td>1057</td>\n",
       "      <td>246.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1057.0</td>\n",
       "      <td>1057</td>\n",
       "      <td>1953</td>\n",
       "      <td>...</td>\n",
       "      <td>731.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NAmes</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>1Story</td>\n",
       "      <td>7</td>\n",
       "      <td>Typ</td>\n",
       "      <td>WD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>174000</td>\n",
       "      <td>318</td>\n",
       "      <td>5</td>\n",
       "      <td>1444</td>\n",
       "      <td>400.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>744</td>\n",
       "      <td>2006</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>Timber</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>2Story</td>\n",
       "      <td>5</td>\n",
       "      <td>Typ</td>\n",
       "      <td>WD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>138500</td>\n",
       "      <td>255</td>\n",
       "      <td>6</td>\n",
       "      <td>1445</td>\n",
       "      <td>484.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>831</td>\n",
       "      <td>1900</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>SawyerW</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>1.5Fin</td>\n",
       "      <td>8</td>\n",
       "      <td>Typ</td>\n",
       "      <td>WD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  SalePrice   Id  Overall Qual  Gr Liv Area  Garage Area  \\\n",
       "0           0     130500  109             6         1479        475.0   \n",
       "1           1     220000  544             7         2122        559.0   \n",
       "2           2     109000  153             5         1057        246.0   \n",
       "3           3     174000  318             5         1444        400.0   \n",
       "4           4     138500  255             6         1445        484.0   \n",
       "\n",
       "   Garage Cars  Total Bsmt SF  1st Flr SF  Year Built  ...  BsmtFin SF 1  \\\n",
       "0          2.0          725.0         725        1976  ...         533.0   \n",
       "1          2.0          913.0         913        1996  ...         637.0   \n",
       "2          1.0         1057.0        1057        1953  ...         731.0   \n",
       "3          2.0          384.0         744        2006  ...           0.0   \n",
       "4          2.0          676.0         831        1900  ...           0.0   \n",
       "\n",
       "   Wood Deck SF  Neighborhood  Condition 1  Condition 2  Bldg Type  \\\n",
       "0             0        Sawyer         RRAe         Norm       1Fam   \n",
       "1             0       SawyerW         Norm         Norm       1Fam   \n",
       "2             0         NAmes         Norm         Norm       1Fam   \n",
       "3           100        Timber         Norm         Norm       1Fam   \n",
       "4             0       SawyerW         Norm         Norm       1Fam   \n",
       "\n",
       "  House Style Overall Cond Functional Sale Type  \n",
       "0      2Story            8        Typ       WD   \n",
       "1      2Story            5        Typ       WD   \n",
       "2      1Story            7        Typ       WD   \n",
       "3      2Story            5        Typ       WD   \n",
       "4      1.5Fin            8        Typ       WD   \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "99215b86-a717-48c1-8834-d403365a8666",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df5_X = df5.drop(columns=['Unnamed: 0', 'Id', 'SalePrice'])\n",
    "df5_y = df5['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fe39d3c6-9260-43fb-b5db-46270aa399a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X5_train, X5_test, y5_train, y5_test = train_test_split(df5_X, df5_y, test_size= 0.2, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0dad5bca-b263-4afa-83b0-dfc3d469502f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df5_train_str = list(X5_train.select_dtypes(include=['object']).columns)\n",
    "df5_test_str = list(X5_test.select_dtypes(include=['object']).columns)\n",
    "df5_train_num = list(X5_train.select_dtypes(include=['int', 'float']).columns)\n",
    "df5_test_num = list(X5_test.select_dtypes(include=['int', 'float']).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53345ab-8216-40b2-b65a-0d6b75531dd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "49e5b776-ddc3-4aee-8f48-ba6f2b45dae8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nPolynomialFeatures does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[57], line 11\u001b[0m\n\u001b[0;32m      4\u001b[0m ct \u001b[38;5;241m=\u001b[39m ColumnTransformer([\n\u001b[0;32m      5\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpoly\u001b[39m\u001b[38;5;124m'\u001b[39m, PolynomialFeatures(include_bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m), df5_num),\n\u001b[0;32m      6\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscaler\u001b[39m\u001b[38;5;124m'\u001b[39m, StandardScaler(), df5_num),\n\u001b[0;32m      7\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moh\u001b[39m\u001b[38;5;124m'\u001b[39m, OneHotEncoder(sparse_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfirst\u001b[39m\u001b[38;5;124m'\u001b[39m), df5_str)\n\u001b[0;32m      8\u001b[0m ], remainder\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Fit and transform the training data using the ColumnTransformer\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m X5_train_transformed \u001b[38;5;241m=\u001b[39m ct\u001b[38;5;241m.\u001b[39mfit_transform(X5_train)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Transform the test data using the fitted ColumnTransformer\u001b[39;00m\n\u001b[0;32m     14\u001b[0m X5_test_transformed \u001b[38;5;241m=\u001b[39m ct\u001b[38;5;241m.\u001b[39mtransform(X5_test)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:743\u001b[0m, in \u001b[0;36mColumnTransformer.fit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    740\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_column_callables(X)\n\u001b[0;32m    741\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_remainder(X)\n\u001b[1;32m--> 743\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_transform(X, y, _fit_transform_one)\n\u001b[0;32m    745\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result:\n\u001b[0;32m    746\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_fitted_transformers([])\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:670\u001b[0m, in \u001b[0;36mColumnTransformer._fit_transform\u001b[1;34m(self, X, y, func, fitted, column_as_strings)\u001b[0m\n\u001b[0;32m    664\u001b[0m transformers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[0;32m    665\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter(\n\u001b[0;32m    666\u001b[0m         fitted\u001b[38;5;241m=\u001b[39mfitted, replace_strings\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, column_as_strings\u001b[38;5;241m=\u001b[39mcolumn_as_strings\n\u001b[0;32m    667\u001b[0m     )\n\u001b[0;32m    668\u001b[0m )\n\u001b[0;32m    669\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 670\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Parallel(n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)(\n\u001b[0;32m    671\u001b[0m         delayed(func)(\n\u001b[0;32m    672\u001b[0m             transformer\u001b[38;5;241m=\u001b[39mclone(trans) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fitted \u001b[38;5;28;01melse\u001b[39;00m trans,\n\u001b[0;32m    673\u001b[0m             X\u001b[38;5;241m=\u001b[39m_safe_indexing(X, column, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m    674\u001b[0m             y\u001b[38;5;241m=\u001b[39my,\n\u001b[0;32m    675\u001b[0m             weight\u001b[38;5;241m=\u001b[39mweight,\n\u001b[0;32m    676\u001b[0m             message_clsname\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumnTransformer\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    677\u001b[0m             message\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_message(name, idx, \u001b[38;5;28mlen\u001b[39m(transformers)),\n\u001b[0;32m    678\u001b[0m         )\n\u001b[0;32m    679\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m idx, (name, trans, column, weight) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(transformers, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    680\u001b[0m     )\n\u001b[0;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    682\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got 1D array instead\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1085\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1076\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1077\u001b[0m     \u001b[38;5;66;03m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[0;32m   1078\u001b[0m     \u001b[38;5;66;03m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1082\u001b[0m     \u001b[38;5;66;03m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[0;32m   1083\u001b[0m     \u001b[38;5;66;03m# remaining jobs.\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m-> 1085\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1088\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mapply_async(batch, callback\u001b[38;5;241m=\u001b[39mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m batch()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py:950\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[0;32m    949\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transformer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 950\u001b[0m         res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mfit_transform(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    951\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    952\u001b[0m         res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:915\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    911\u001b[0m \u001b[38;5;66;03m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[0;32m    912\u001b[0m \u001b[38;5;66;03m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[0;32m    913\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    914\u001b[0m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[1;32m--> 915\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    917\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m    918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py:322\u001b[0m, in \u001b[0;36mPolynomialFeatures.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    304\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    306\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;124;03m    Compute number of output features.\u001b[39;00m\n\u001b[0;32m    308\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    320\u001b[0m \u001b[38;5;124;03m        Fitted transformer.\u001b[39;00m\n\u001b[0;32m    321\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 322\u001b[0m     _, n_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(X, accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m    324\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdegree, Integral):\n\u001b[0;32m    325\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdegree \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minclude_bias:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:604\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    602\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    603\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 604\u001b[0m     out \u001b[38;5;241m=\u001b[39m check_array(X, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    605\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[0;32m    606\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:959\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    953\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    954\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    955\u001b[0m             \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    956\u001b[0m         )\n\u001b[0;32m    958\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[1;32m--> 959\u001b[0m         _assert_all_finite(\n\u001b[0;32m    960\u001b[0m             array,\n\u001b[0;32m    961\u001b[0m             input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[0;32m    962\u001b[0m             estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[0;32m    963\u001b[0m             allow_nan\u001b[38;5;241m=\u001b[39mforce_all_finite \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    964\u001b[0m         )\n\u001b[0;32m    966\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    967\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:124\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 124\u001b[0m _assert_all_finite_element_wise(\n\u001b[0;32m    125\u001b[0m     X,\n\u001b[0;32m    126\u001b[0m     xp\u001b[38;5;241m=\u001b[39mxp,\n\u001b[0;32m    127\u001b[0m     allow_nan\u001b[38;5;241m=\u001b[39mallow_nan,\n\u001b[0;32m    128\u001b[0m     msg_dtype\u001b[38;5;241m=\u001b[39mmsg_dtype,\n\u001b[0;32m    129\u001b[0m     estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[0;32m    130\u001b[0m     input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[0;32m    131\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:173\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[1;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    159\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    160\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    161\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    171\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    172\u001b[0m     )\n\u001b[1;32m--> 173\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input X contains NaN.\nPolynomialFeatures does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "imputer = SimpleImputer(strategy='mean')\n",
    "X5_train_transformed = imputer.fit_transform(X5_train[df5_train_num])\n",
    "\n",
    "\n",
    "ct = ColumnTransformer([\n",
    "    ('poly', PolynomialFeatures(include_bias=False), X5_train_transformed),\n",
    "    ('scaler', StandardScaler(), X5_train_transformed),\n",
    "    ('oh', OneHotEncoder(sparse_output=False, drop='first'), df5_str)\n",
    "], remainder='passthrough')\n",
    "\n",
    "# Fit and transform the training data using the ColumnTransformer\n",
    "X5_train_transformed = ct.fit_transform(X5_train)\n",
    "\n",
    "# Transform the test data using the fitted ColumnTransformer\n",
    "X5_test_transformed = ct.transform(X5_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2693728b-65c1-4fb9-a899-c6e8f612a97b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9441911420782777\n",
      "0.8324015525042832\n",
      "941538570.8963733\n"
     ]
    }
   ],
   "source": [
    "df6 = pd.read_csv('datasets/df5.csv')\n",
    "\n",
    "df6 = df6.dropna()\n",
    "\n",
    "df6_X = df6.drop(columns=['Unnamed: 0', 'Id', 'SalePrice'])\n",
    "df6_y = df6['SalePrice']\n",
    "\n",
    "X6_train, X6_test, y6_train, y6_test = train_test_split(df6_X, df6_y, test_size= 0.2, random_state=4)\n",
    "\n",
    "df6_train_str = list(X6_train.select_dtypes(include=['object']).columns)\n",
    "df6_test_str = list(X6_test.select_dtypes(include=['object']).columns)\n",
    "df6_train_num = list(X6_train.select_dtypes(include=['int', 'float']).columns)\n",
    "df6_test_num = list(X6_test.select_dtypes(include=['int', 'float']).columns)\n",
    "\n",
    "ct = ColumnTransformer([\n",
    "    ('poly', PolynomialFeatures(include_bias=False), df6_train_num),\n",
    "    ('scaler', StandardScaler(), df6_train_num),\n",
    "    ('oh', OneHotEncoder(sparse_output=False, drop='first'), df6_train_str)\n",
    "], remainder='passthrough')\n",
    "\n",
    "# Fit and transform the training data using the ColumnTransformer\n",
    "X6_train_transformed = ct.fit_transform(X6_train)\n",
    "\n",
    "# Transform the test data using the fitted ColumnTransformer\n",
    "X6_test_transformed = ct.transform(X6_test)\n",
    "\n",
    "lr6 = LinearRegression()\n",
    "\n",
    "lr6.fit(X6_train_transformed, y6_train)\n",
    "\n",
    "r2_train = lr6.score(X6_train_transformed, y6_train)\n",
    "\n",
    "r2_test = lr6.score(X6_test_transformed, y6_test)\n",
    "\n",
    "y6_pred = lr6.predict(X6_test_transformed)\n",
    "\n",
    "print(r2_train)\n",
    "print(r2_test)\n",
    "print(metrics.mean_squared_error(y6_test, y6_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "99a98338-4bda-46a3-bd52-2dd955f3afa4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kaitl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.690e+11, tolerance: 8.432e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\kaitl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.770e+11, tolerance: 8.004e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\kaitl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.619e+11, tolerance: 8.256e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\kaitl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.591e+11, tolerance: 8.357e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\kaitl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.843e+11, tolerance: 8.605e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\kaitl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.643e+11, tolerance: 8.432e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\kaitl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.721e+11, tolerance: 8.004e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\kaitl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.571e+11, tolerance: 8.256e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\kaitl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.542e+11, tolerance: 8.357e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\kaitl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.797e+11, tolerance: 8.605e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\kaitl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.586e+11, tolerance: 8.432e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\kaitl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.662e+11, tolerance: 8.004e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\kaitl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.511e+11, tolerance: 8.256e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\kaitl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.481e+11, tolerance: 8.357e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\kaitl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.740e+11, tolerance: 8.605e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\kaitl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.507e+11, tolerance: 8.432e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\kaitl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.584e+11, tolerance: 8.004e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\kaitl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.431e+11, tolerance: 8.256e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\kaitl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.400e+11, tolerance: 8.357e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\kaitl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.662e+11, tolerance: 8.605e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\kaitl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.376e+11, tolerance: 8.432e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\kaitl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.461e+11, tolerance: 8.004e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\kaitl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.302e+11, tolerance: 8.256e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\kaitl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.270e+11, tolerance: 8.357e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\kaitl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.534e+11, tolerance: 8.605e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\kaitl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.127e+11, tolerance: 8.432e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\kaitl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.245e+11, tolerance: 8.004e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\kaitl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.077e+11, tolerance: 8.256e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\kaitl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.036e+11, tolerance: 8.357e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\kaitl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.253e+11, tolerance: 8.605e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\kaitl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.086e+11, tolerance: 8.432e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\kaitl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.199e+11, tolerance: 8.004e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\kaitl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.034e+11, tolerance: 8.256e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\kaitl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.995e+11, tolerance: 8.357e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\kaitl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.215e+11, tolerance: 8.605e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\kaitl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.026e+11, tolerance: 8.432e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\kaitl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.134e+11, tolerance: 8.004e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\kaitl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.972e+11, tolerance: 8.256e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\kaitl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.936e+11, tolerance: 8.357e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\kaitl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.161e+11, tolerance: 8.605e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\kaitl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.929e+11, tolerance: 8.432e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\kaitl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.027e+11, tolerance: 8.004e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\kaitl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.870e+11, tolerance: 8.256e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\kaitl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.838e+11, tolerance: 8.357e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\kaitl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.071e+11, tolerance: 8.605e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\kaitl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.710e+11, tolerance: 8.432e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\kaitl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.791e+11, tolerance: 8.004e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\kaitl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.640e+11, tolerance: 8.256e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\kaitl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.612e+11, tolerance: 8.357e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\kaitl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.863e+11, tolerance: 8.605e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\kaitl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.360e+11, tolerance: 8.432e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\kaitl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.509e+11, tolerance: 8.004e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\kaitl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.307e+11, tolerance: 8.256e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\kaitl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.256e+11, tolerance: 8.357e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\kaitl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.460e+11, tolerance: 8.605e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\kaitl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.346e+11, tolerance: 8.432e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\kaitl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.493e+11, tolerance: 8.004e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\kaitl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.295e+11, tolerance: 8.256e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\kaitl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.244e+11, tolerance: 8.357e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\kaitl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.448e+11, tolerance: 8.605e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\kaitl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.324e+11, tolerance: 8.432e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\kaitl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.467e+11, tolerance: 8.004e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\kaitl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.274e+11, tolerance: 8.256e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\kaitl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.224e+11, tolerance: 8.357e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\kaitl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.428e+11, tolerance: 8.605e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\kaitl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.281e+11, tolerance: 8.432e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\kaitl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.418e+11, tolerance: 8.004e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\kaitl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.233e+11, tolerance: 8.256e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\kaitl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.184e+11, tolerance: 8.357e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\kaitl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.390e+11, tolerance: 8.605e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\kaitl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.145e+11, tolerance: 8.432e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\kaitl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.264e+11, tolerance: 8.004e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\kaitl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.095e+11, tolerance: 8.256e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\kaitl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.053e+11, tolerance: 8.357e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\kaitl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.268e+11, tolerance: 8.605e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\kaitl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.418e+11, tolerance: 8.432e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\kaitl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.566e+11, tolerance: 8.004e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\kaitl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.349e+11, tolerance: 8.256e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\kaitl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.297e+11, tolerance: 8.357e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\kaitl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.496e+11, tolerance: 8.605e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\kaitl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.415e+11, tolerance: 8.432e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\kaitl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.564e+11, tolerance: 8.004e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\kaitl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.348e+11, tolerance: 8.256e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\kaitl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.295e+11, tolerance: 8.357e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\kaitl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.495e+11, tolerance: 8.605e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\kaitl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.411e+11, tolerance: 8.432e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\kaitl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.561e+11, tolerance: 8.004e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\kaitl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.345e+11, tolerance: 8.256e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\kaitl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.293e+11, tolerance: 8.357e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\kaitl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.494e+11, tolerance: 8.605e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\kaitl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.402e+11, tolerance: 8.432e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\kaitl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.553e+11, tolerance: 8.004e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\kaitl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.341e+11, tolerance: 8.256e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\kaitl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.288e+11, tolerance: 8.357e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\kaitl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.491e+11, tolerance: 8.605e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\kaitl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.367e+11, tolerance: 8.432e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\kaitl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.517e+11, tolerance: 8.004e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\kaitl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.314e+11, tolerance: 8.256e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\kaitl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.263e+11, tolerance: 8.357e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\kaitl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.466e+11, tolerance: 8.605e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha: 0.01\n",
      "Best l1_ratio: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kaitl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.445e+11, tolerance: 1.041e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "df6 = pd.read_csv('datasets/df5.csv')\n",
    "df6 = df6.dropna()\n",
    "df6_X = df6.drop(columns=['Unnamed: 0', 'Id', 'SalePrice'])\n",
    "df6_y = df6['SalePrice']\n",
    "X6_train, X6_test, y6_train, y6_test = train_test_split(df6_X, df6_y, test_size=0.2, random_state=4)\n",
    "df6_train_str = list(X6_train.select_dtypes(include=['object']).columns)\n",
    "df6_test_str = list(X6_test.select_dtypes(include=['object']).columns)\n",
    "df6_train_num = list(X6_train.select_dtypes(include=['int', 'float']).columns)\n",
    "df6_test_num = list(X6_test.select_dtypes(include=['int', 'float']).columns)\n",
    "\n",
    "# Create a ColumnTransformer with PolynomialFeatures, StandardScaler, and OneHotEncoder\n",
    "ct = ColumnTransformer([\n",
    "    ('poly', PolynomialFeatures(include_bias=False), df6_train_num),\n",
    "    ('scaler', StandardScaler(), df6_train_num),\n",
    "    ('oh', OneHotEncoder(sparse_output=False, drop='first'), df6_train_str)\n",
    "], remainder='passthrough')\n",
    "\n",
    "# Fit and transform the training data using the ColumnTransformer\n",
    "X6_train_transformed = ct.fit_transform(X6_train)\n",
    "\n",
    "# Transform the test data using the fitted ColumnTransformer\n",
    "X6_test_transformed = ct.transform(X6_test)\n",
    "\n",
    "# Create an ElasticNet model\n",
    "elastic_net = ElasticNet()\n",
    "param_grid = {\n",
    "    'alpha': [0.01, 0.1, 1.0, 10.0],      # Values of alpha to test\n",
    "    'l1_ratio': [0.1, 0.3, 0.5, 0.7, 0.9]  # Values of l1_ratio to test\n",
    "}\n",
    "\n",
    "# Create a GridSearchCV object\n",
    "grid_search = GridSearchCV(estimator=elastic_net, param_grid=param_grid, cv=5)\n",
    "\n",
    "# Fit the GridSearchCV object to the training data\n",
    "grid_search.fit(X6_train_transformed, y6_train)\n",
    "\n",
    "# Get the best hyperparameters from the search\n",
    "best_alpha = grid_search.best_params_['alpha']\n",
    "best_l1_ratio = grid_search.best_params_['l1_ratio']\n",
    "\n",
    "print(f\"Best alpha: {best_alpha}\")\n",
    "print(f\"Best l1_ratio: {best_l1_ratio}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "bfe91604-46c4-4e71-bc30-9c659c8192a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training R-squared: 0.9379529125451435\n",
      "Test R-squared: 0.8183911458714808\n",
      "Mean Squared Error: 1020246568.7080061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kaitl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.445e+11, tolerance: 1.041e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "df6 = pd.read_csv('datasets/df5.csv')\n",
    "df6 = df6.dropna()\n",
    "df6_X = df6.drop(columns=['Unnamed: 0', 'Id', 'SalePrice'])\n",
    "df6_y = df6['SalePrice']\n",
    "X6_train, X6_test, y6_train, y6_test = train_test_split(df6_X, df6_y, test_size=0.2, random_state=4)\n",
    "df6_train_str = list(X6_train.select_dtypes(include=['object']).columns)\n",
    "df6_test_str = list(X6_test.select_dtypes(include=['object']).columns)\n",
    "df6_train_num = list(X6_train.select_dtypes(include=['int', 'float']).columns)\n",
    "df6_test_num = list(X6_test.select_dtypes(include=['int', 'float']).columns)\n",
    "\n",
    "# Create a ColumnTransformer with PolynomialFeatures, StandardScaler, and OneHotEncoder\n",
    "ct = ColumnTransformer([\n",
    "    ('poly', PolynomialFeatures(include_bias=False), df6_train_num),\n",
    "    ('scaler', StandardScaler(), df6_train_num),\n",
    "    ('oh', OneHotEncoder(sparse_output=False, drop='first'), df6_train_str)\n",
    "], remainder='passthrough')\n",
    "\n",
    "# Fit and transform the training data using the ColumnTransformer\n",
    "X6_train_transformed = ct.fit_transform(X6_train)\n",
    "\n",
    "# Transform the test data using the fitted ColumnTransformer\n",
    "X6_test_transformed = ct.transform(X6_test)\n",
    "\n",
    "# Create an ElasticNet model with regularization\n",
    "elastic_net = ElasticNet(alpha=.01, l1_ratio=0.5)  # You can adjust alpha and l1_ratio as needed\n",
    "\n",
    "# Fit the ElasticNet model to the training data\n",
    "elastic_net.fit(X6_train_transformed, y6_train)\n",
    "\n",
    "# Calculate the R-squared score on the training and test data\n",
    "train_score = elastic_net.score(X6_train_transformed, y6_train)\n",
    "test_score = elastic_net.score(X6_test_transformed, y6_test)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y6_pred = elastic_net.predict(X6_test_transformed)\n",
    "\n",
    "# Calculate the mean squared error\n",
    "mse = metrics.mean_squared_error(y6_test, y6_pred)\n",
    "\n",
    "print(f\"Training R-squared: {train_score}\")\n",
    "print(f\"Test R-squared: {test_score}\")\n",
    "print(f\"Mean Squared Error: {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "09a2885d-bc78-42c1-bf2c-5bedbd5895f5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training R-squared: 0.9418459116453659\n",
      "Test R-squared: 0.8214326923203195\n",
      "Mean Squared Error: 1003159696.248595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kaitl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.028e+11, tolerance: 1.041e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "df6 = pd.read_csv('datasets/df5.csv')\n",
    "df6 = df6.dropna()\n",
    "df6_X = df6.drop(columns=['Unnamed: 0', 'Id', 'SalePrice'])\n",
    "df6_y = df6['SalePrice']\n",
    "X6_train, X6_test, y6_train, y6_test = train_test_split(df6_X, df6_y, test_size=0.2, random_state=4)\n",
    "df6_train_str = list(X6_train.select_dtypes(include=['object']).columns)\n",
    "df6_test_str = list(X6_test.select_dtypes(include=['object']).columns)\n",
    "df6_train_num = list(X6_train.select_dtypes(include=['int', 'float']).columns)\n",
    "df6_test_num = list(X6_test.select_dtypes(include=['int', 'float']).columns)\n",
    "\n",
    "# Create a ColumnTransformer with PolynomialFeatures, StandardScaler, and OneHotEncoder\n",
    "ct = ColumnTransformer([\n",
    "    ('poly', PolynomialFeatures(include_bias=False), df6_train_num),\n",
    "    ('scaler', StandardScaler(), df6_train_num),\n",
    "    ('oh', OneHotEncoder(sparse_output=False, drop='first'), df6_train_str)\n",
    "], remainder='passthrough')\n",
    "\n",
    "# Fit and transform the training data using the ColumnTransformer\n",
    "X6_train_transformed = ct.fit_transform(X6_train)\n",
    "\n",
    "# Transform the test data using the fitted ColumnTransformer\n",
    "X6_test_transformed = ct.transform(X6_test)\n",
    "\n",
    "# Create a Lasso model with regularization\n",
    "lasso = Lasso(alpha=.01)  # You can adjust the alpha parameter as needed\n",
    "\n",
    "# Fit the Lasso model to the training data\n",
    "lasso.fit(X6_train_transformed, y6_train)\n",
    "\n",
    "# Calculate the R-squared score on the training and test data\n",
    "train_score = lasso.score(X6_train_transformed, y6_train)\n",
    "test_score = lasso.score(X6_test_transformed, y6_test)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y6_pred = lasso.predict(X6_test_transformed)\n",
    "\n",
    "# Calculate the mean squared error\n",
    "mse = metrics.mean_squared_error(y6_test, y6_pred)\n",
    "\n",
    "print(f\"Training R-squared: {train_score}\")\n",
    "print(f\"Test R-squared: {test_score}\")\n",
    "print(f\"Mean Squared Error: {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b13189-164a-4aea-9a43-914a675f97b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
